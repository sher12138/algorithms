$$
Algorithm: DecisionTransformDifficulty
Input: \\

    d_i: 当前帧自车对障碍物i的决策概率 \\
    d_i^{-1}: 上一帧自车对障碍物i的决策概率 \\
    T^{-1}\{t_0,t_1,...\}:上一帧规划的轨迹 \\
Output:  \\
    TransformNeedS: 决策转换的增量s \\

    1: B = [1..n]    // Initialize B as a list of n obstacles \\ 
    2: for i = 1 to n do \\
    3:    T^{-1}_{rev}\{t_0,t_1,...\} = GenerateReverseDecisionTrajectory(d_i^{-1}, T^{-1}\{t_0,t_1,...\}) \\
    4:    TransformNeedS = StaticTransformNeedS(T^{-1}_{rev}\{t_0,t_1,...\} ,T^{-1}\{t_0,t_1,...\}) \\

Algorithm:GenerateReverseDecisionTrajectory \\ 
Input:  \\
    d_i^{-1}: 上一帧自车对障碍物i的决策概率 \\ 
    T^{-1}\{t_0,t_1,...\}:上一帧规划的轨迹 \\
Output: \\
    T^{-1}_{rev}\{t_0,t_1,...\}:上一帧规划的轨迹的反向决策轨迹  \\
    return GenerateDecisionTrajectory(1- d^{-1}_i) \\ 


Algorithm:GenerateDecisionTrajectory \\ 
Input: \\ 
    d_i: 当前帧自车对障碍物i的决策概率 \\ \\
Output: \\
    T\{t_0,t_1,...\}:上一帧规划的轨迹

    1. D_i = EvolutionaryDecision(d_i) \\ 绘制演化相图，得到收敛决策结果
    2. if D_i == 0 then \\
    3.   T\{t_0,t_1,...\} = IDM(o_i) \\ 对于让行问题，使用IDM模型求解跟车轨迹
    4. else if D_i == 1 then \\
    5.  T\{t_0,t_1,...\} = OBVP(o_i) \\ 对于抢行场景，采用终点状态求解OBVP问题获得轨迹。
    6. return T\{t_0,t_1,...\} \\



Algorithm:StaticTransformNeedS \\ 
Input: \\
    T^{-1}_{rev}\{t_{0,rev},t_{1,rev},...\} :上一帧规划的轨迹的反向决策轨迹 \\
    T^{-1}\{t_0,t_1,...\}:上一帧规划的轨迹 \\
Output: \\
    NeedS: 障碍物i对自车的决策转换增量S \\
    return TransformNeedS = \int_{t_0}^{t_n}(S(t)dt) -  \int_{t_{0,rev}}^{t_{n,rev}}(S(t)dt)  \\

$$