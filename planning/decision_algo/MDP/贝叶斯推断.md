## 贝叶斯定理
各个事件之间是相互独立的，即事件A和事件B之间没有任何关系。如果事件A发生了，那么事件B发生的概率不会发生任何变化。这种情况下，我们可以使用条件概率来计算事件B发生的概率。条件概率的计算公式如下：
$$
P(A|B) = \frac{P(B|A)P(A)}{P(B)}
$$
$$P(A\mid B_1B_2\ldots B_n)=\prod_{i=1}^n\frac{P(B_i\mid A)}{P(B_i)}P(A)$$

## 统计学派

### 频率学派:
在频率学派的视角中，概率是固定的，它导致数据结果的随机，例如抛硬币抛出来的结果是随机的（但符合大数定律），可通过多次实验结果推断出正反面概率这个固定值

### 贝叶斯学派
数据结果是固定的，而导致它的概率是随机的，例如我们只能认定抛硬币的结果是完全已知，决定结果的正反面概率是个随机概率，可通过先验分布（正反面均为1/2）、似然函数和后验分布（实验结果）的不断拟合优化推断出概率分布

## 贝叶斯推断：贝叶斯变分，贝叶斯网络

*频率学派*
$$X:\text{Data},\quad\theta:\text{Certain Unknown Parameter},\quad f(X|\theta),\quad g(X)\to\theta\quad\text{(Frequency)}$$

- X 数据 
- $\theta$ 未知参数
频率学派：
- $f(X|\theta)$ 数据的分布，参数看成确定未知量。此时用数据来估计参数。即统计 $g(X)$，统计对参数做估计。



*贝叶斯学派*
$$X\leftrightarrow\theta\text{ Symmetric},\quad\theta\sim P(\theta)\text{Prior},\quad P(X|\theta)\text{Liklihood},\quad\Rightarrow P(\theta|X)\text{Posterior}\quad\text{(Beyasian)}$$

贝叶斯学派：数据参数对称，同为随机变量，参数有先验分布。此时用数据来更新参数的分布。即贝叶斯推断。
- $g(X)$ 数据的分布，参数看成随机变量。此时用数据来更新参数的分布。即贝叶斯推断。
通过先验分布 + 模型 --> 后验分布 

变分贝叶斯：变分推断是一种近似推断方法，它通过最小化两个分布之间的差异来近似真实后验分布。变分推断的目标是找到一个近似分布，使得它与真实后验分布的KL散度最小。变分推断的核心思想是将真实后验分布表示为一个参数化的分布族，然后通过优化参数来使得近似分布与真实后验分布的KL散度最小。

KL散度：KL散度是两个概率分布之间的相对熵，用于衡量两个分布之间的差异。KL散度的定义如下：
$$D_{KL}(P||Q) = \sum_{x}P(x)\log\frac{P(x)}{Q(x)}$$

变分以函数为自变量的优化：
$$\min_{q\in Q}D_{KL}(q(\theta)||p(\theta|X))$$